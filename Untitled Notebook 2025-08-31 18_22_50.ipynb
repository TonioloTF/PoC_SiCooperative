{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa752d2-3012-4ba7-ac60-f76eb227ab33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0275f3d3-99ff-4a3b-95c0-4f102adf664e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parâmetros de conexão com PostgreSQL\n",
    "host = \"dpg-d2q93uv5r7bs73aesqlg-a.oregon-postgres.render.com\"\n",
    "port = 5432\n",
    "database = \"sicoop\"\n",
    "user = \"admin\"\n",
    "password = \"vnbygROdVav9q0C5gqF6S7zJjieM7hIr\"\n",
    "\n",
    "def create_spark_session():\n",
    "    \"\"\"Cria e configura o SparkSession com suporte ao driver PostgreSQL JDBC\"\"\"\n",
    "    \n",
    "    # Configurar variáveis de ambiente para o driver JDBC\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars drivers/postgresql-42.7.7.jar pyspark-shell'\n",
    "    \n",
    "    # Criar SparkSession\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ETL_Sicoop_PostgreSQL\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .config(\"spark.executor.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    print(\"SparkSession criada com sucesso!\")\n",
    "    print(f\"Versão do Spark: {spark.version}\")\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d22535e-58da-4996-9685-3375b9d73bf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defina os detalhes da sua base de dados PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://dpg-d2q93uv5r7bs73aesqlg-a.oregon-postgres.render.com:5432/sicoop\"\n",
    "user = \"admin\"\n",
    "password = \"vnbygROdVav9q0C5gqF6S7zJjieM7hIr\"\n",
    "driver = \"org.postgresql.Driver\"\n",
    "\n",
    "# Especifique o caminho para o driver JDBC no Databricks\n",
    "# (O caminho exato dependerá de onde você o carregou)\n",
    "# Este é um passo crucial que precisa ser ajustado à sua configuração\n",
    "driver_path = \"/drivers/postgresql-42.7.7.jar\" # Exemplo\n",
    "\n",
    "# Registre o driver e crie a conexão\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgresqlJDBCConnection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# O caminho para o driver deve ser especificado em SparkConf\n",
    "spark.conf.set(\"spark.jars\", driver_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-08-31 18_22_50",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
