{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5f0ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pandas\n",
    "#pip install pyspark==4.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b04a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas necessárias\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import date_format, col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Parâmetros de conexão com PostgreSQL\n",
    "host = \"dpg-d2q93uv5r7bs73aesqlg-a.oregon-postgres.render.com\"\n",
    "port = 5432\n",
    "database = \"sicoop\"\n",
    "user = \"admin\"\n",
    "password = \"vnbygROdVav9q0C5gqF6S7zJjieM7hIr\"\n",
    "\n",
    "def create_spark_session():\n",
    "    \n",
    "    print(\"\\nCriando SparkSession...\")\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ETL_Sicoop_PostgreSQL\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .config(\"spark.executor.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Djava.io.tmpdir=C:/temp\") \\\n",
    "        .config(\"spark.executor.extraJavaOptions\", \"-Djava.io.tmpdir=C:/temp\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\") \\\n",
    "        .getOrCreate()\n",
    "        \n",
    "    return spark\n",
    "\n",
    "def configure_postgres_connection():\n",
    "    \n",
    "    print(\"\\nConexão PostgreSQL...\")\n",
    "    \n",
    "    jdbc_url = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "    connection_properties = {\n",
    "        \"user\": user,\n",
    "        \"password\": password,\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "        \n",
    "    return jdbc_url, connection_properties\n",
    "\n",
    "def read_table_from_postgres(spark, jdbc_url, connection_properties, table_name):\n",
    "    \n",
    "    print(f\"Inicia Leitura do Script...\")\n",
    "\n",
    "    df = spark.read.jdbc(\n",
    "        url=jdbc_url, \n",
    "        table=table_name, \n",
    "        properties=connection_properties\n",
    "    )\n",
    "    \n",
    "    print(f\"Número de linhas retornadas na tabela {table_name}: {df.count()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f8e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando SparkSession...\n",
      "\n",
      "Conexão PostgreSQL...\n",
      "Inicia Leitura do Script...\n",
      "Número de linhas retornadas na tabela associado: 100\n",
      "Inicia Leitura do Script...\n",
      "Número de linhas retornadas na tabela conta: 120\n",
      "Inicia Leitura do Script...\n",
      "Número de linhas retornadas na tabela cartao: 240\n",
      "Inicia Leitura do Script...\n",
      "Número de linhas retornadas na tabela movimento: 1000\n"
     ]
    }
   ],
   "source": [
    "# Cria SparkSession\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Configurar conexão PostgreSQL\n",
    "jdbc_url, connection_properties = configure_postgres_connection()\n",
    "\n",
    "# Leitura tabelas\n",
    "df_associado = read_table_from_postgres(spark, jdbc_url, connection_properties, \"associado\")\n",
    "df_conta     = read_table_from_postgres(spark, jdbc_url, connection_properties, \"conta\")\n",
    "df_cartao    = read_table_from_postgres(spark, jdbc_url, connection_properties, \"cartao\")\n",
    "df_movimento = read_table_from_postgres(spark, jdbc_url, connection_properties, \"movimento\")\n",
    "\n",
    "df_query = df_movimento \\\n",
    "    .join(df_cartao.withColumnRenamed(\"data_criacao\", \"data_criacao_cartao\"), \"id_cartao\") \\\n",
    "    .join(df_conta.withColumnRenamed(\"data_criacao\", \"data_criacao_conta\"), \"id_conta\") \\\n",
    "    .join(df_associado, \"id_associado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee11f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_query.groupBy(\n",
    "    \"nome\", \"sobrenome\", \"idade\",\n",
    "    \"des_tranacao\", \"data_movimento\",\n",
    "    \"num_cartao\", \"nom_impresso\",\n",
    "    \"data_criacao_cartao\", \"tipo\", \"data_criacao_conta\"\n",
    ").agg(\n",
    "    F.sum(\"vlr_transacao\").alias(\"vlr_transacao_movimento\")\n",
    ")\n",
    "\n",
    "df_result = df_result.select(\n",
    "    F.col(\"nome\").alias(\"nome_associado\"),\n",
    "    F.col(\"sobrenome\").alias(\"sobrenome_associado\"),\n",
    "    F.col(\"idade\").alias(\"idade_associado\"),\n",
    "    F.col(\"vlr_transacao_movimento\"),\n",
    "    F.col(\"des_tranacao\").alias(\"des_tranacao_movimento\"),\n",
    "    F.col(\"data_movimento\"),\n",
    "    F.col(\"num_cartao\").alias(\"numero_cartao\"),\n",
    "    F.col(\"nom_impresso\").alias(\"nome_impresso_cartao\"),\n",
    "    F.col(\"data_criacao_cartao\"),\n",
    "    F.col(\"tipo\").alias(\"tipo_conta\"),\n",
    "    F.col(\"data_criacao_conta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf983a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter timestamps para string no Spark\n",
    "df_result_treated = df_result\n",
    "for col_name in df_result.columns:\n",
    "    if 'data' in col_name.lower():\n",
    "        df_result_treated = df_result_treated.withColumn(col_name, date_format(col(col_name), 'yyyy-MM-dd HH:mm:ss'))\n",
    "        \n",
    "# Converter para Pandas\n",
    "df_result_output = df_result_treated.toPandas()\n",
    "        \n",
    "# Salvar CSV\n",
    "output_path = \"outputs/movimento_final.csv\"\n",
    "df_result_output.to_csv(output_path, sep=';', index=False, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
