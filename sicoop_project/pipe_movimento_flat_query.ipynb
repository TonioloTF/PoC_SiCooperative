{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5f0ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pandas\n",
    "#pip install pyspark==4.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b04a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas necessárias\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import date_format, col\n",
    "\n",
    "# Parâmetros de conexão com PostgreSQL\n",
    "host = \"dpg-d2q93uv5r7bs73aesqlg-a.oregon-postgres.render.com\"\n",
    "port = 5432\n",
    "database = \"sicoop\"\n",
    "user = \"admin\"\n",
    "password = \"vnbygROdVav9q0C5gqF6S7zJjieM7hIr\"\n",
    "\n",
    "def create_spark_session():\n",
    "    \n",
    "    print(\"\\nCriando SparkSession...\")\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ETL_Sicoop_PostgreSQL\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .config(\"spark.executor.extraClassPath\", \"drivers/postgresql-42.7.7.jar\") \\\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Djava.io.tmpdir=C:/temp\") \\\n",
    "        .config(\"spark.executor.extraJavaOptions\", \"-Djava.io.tmpdir=C:/temp\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\") \\\n",
    "        .getOrCreate()\n",
    "        \n",
    "    return spark\n",
    "\n",
    "def configure_postgres_connection():\n",
    "    \n",
    "    print(\"\\nConexão PostgreSQL...\")\n",
    "    \n",
    "    jdbc_url = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "    connection_properties = {\n",
    "        \"user\": user,\n",
    "        \"password\": password,\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "        \n",
    "    return jdbc_url, connection_properties\n",
    "\n",
    "def read_table_from_postgres(spark, jdbc_url, connection_properties, table_name):\n",
    "    \n",
    "    print(f\"Inicia Leitura do Script...\")\n",
    "\n",
    "    df = spark.read.jdbc(\n",
    "        url=jdbc_url, \n",
    "        table=table_name, \n",
    "        properties=connection_properties\n",
    "    )\n",
    "    \n",
    "    print(f\"Número de linhas retornadas: {df.count()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando SparkSession...\n",
      "\n",
      "Conexão PostgreSQL...\n",
      "Inicia Leitura do Script...\n",
      "Número de linhas retornadas: 1000\n"
     ]
    }
   ],
   "source": [
    "# Cria SparkSession\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Configurar conexão PostgreSQL\n",
    "jdbc_url, connection_properties = configure_postgres_connection()\n",
    "\n",
    "query = \"\"\"\n",
    "(\n",
    "    select \t\n",
    "        ass.nome              nome_associado,\n",
    "        ass.sobrenome         sobrenome_associado,\n",
    "        ass.idade             idade_associado,\n",
    "        sum(mov.vlr_transacao) vlr_transacao_movimento,\n",
    "        mov.des_tranacao      des_tranacao_movimento,\n",
    "        mov.data_movimento    data_movimento,\n",
    "        crt.num_cartao        numero_cartao,\n",
    "        crt.nom_impresso      nome_impresso_cartao,\n",
    "        crt.data_criacao      data_criacao_cartao,\n",
    "        cnt.tipo              tipo_conta,\n",
    "        cnt.data_criacao      data_criacao_conta\n",
    "    from \t\n",
    "        movimento mov\n",
    "        inner join cartao crt\n",
    "            on mov.id_cartao = crt.id_cartao \n",
    "        inner join conta cnt\n",
    "            on crt.id_conta  = cnt.id_conta\n",
    "        inner join associado ass\n",
    "            on cnt.id_associado = ass.id_associado \n",
    "    group by\n",
    "        ass.nome,\n",
    "        ass.sobrenome,\n",
    "        ass.idade,\n",
    "        mov.des_tranacao,\n",
    "        mov.data_movimento,\n",
    "        crt.num_cartao,\n",
    "        crt.nom_impresso,\n",
    "        crt.data_criacao,\n",
    "        cnt.tipo,\n",
    "        cnt.data_criacao\n",
    ") as consulta\n",
    "\"\"\"\n",
    "\n",
    "df_movimento =  read_table_from_postgres(spark, jdbc_url, connection_properties, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cf983a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter timestamps para string no Spark\n",
    "df_movimento_treated = df_movimento\n",
    "for col_name in df_movimento.columns:\n",
    "    if 'data' in col_name.lower():\n",
    "        df_movimento_treated = df_movimento_treated.withColumn(col_name, date_format(col(col_name), 'yyyy-MM-dd HH:mm:ss'))\n",
    "        \n",
    "# Converter para Pandas\n",
    "df_movimento_output = df_movimento_treated.toPandas()\n",
    "        \n",
    "# Salvar CSV\n",
    "output_path = \"output/movimento_final.csv\"\n",
    "df_movimento_output.to_csv(output_path, sep=';', index=False, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
